{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 线性代数\n",
    "\n",
    "标量由只有一个元素的张量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[], dtype=Float32, value= 5),\n",
       " Tensor(shape=[], dtype=Float32, value= 6),\n",
       " Tensor(shape=[], dtype=Float32, value= 1.5),\n",
       " Tensor(shape=[], dtype=Float32, value= 9))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import easy_mindspore as ems\n",
    "import mindspore\n",
    "\n",
    "x = ems.tensor(3.0)\n",
    "y = ems.tensor(2.0)\n",
    "\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "你可以将向量视为标量值组成的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[4], dtype=Int32, value= [0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ems.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "通过张量的索引来访问任一元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[], dtype=Int32, value= 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "访问张量的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "只有一个轴的张量，形状只有一个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "通过指定两个分量$m$和$n$来创建一个形状为$m \\times n$的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[5, 4], dtype=Int32, value=\n",
       "[[ 0,  1,  2,  3],\n",
       " [ 4,  5,  6,  7],\n",
       " [ 8,  9, 10, 11],\n",
       " [12, 13, 14, 15],\n",
       " [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = ems.arange(20).reshape(5, 4)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "矩阵的转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[4, 5], dtype=Int32, value=\n",
       "[[ 0,  4,  8, 12, 16],\n",
       " [ 1,  5,  9, 13, 17],\n",
       " [ 2,  6, 10, 14, 18],\n",
       " [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*对称矩阵*（symmetric matrix）$\\mathbf{A}$等于其转置：$\\mathbf{A} = \\mathbf{A}^\\top$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[3, 3], dtype=Int32, value=\n",
       "[[1, 2, 3],\n",
       " [2, 0, 4],\n",
       " [3, 4, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = ems.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[3, 3], dtype=Bool, value=\n",
       "[[ True,  True,  True],\n",
       " [ True,  True,  True],\n",
       " [ True,  True,  True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B == B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "就像向量是标量的推广，矩阵是向量的推广一样，我们可以构建具有更多轴的数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "origin_pos": 38,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2, 3, 4], dtype=Int32, value=\n",
       "[[[ 0,  1,  2,  3],\n",
       "  [ 4,  5,  6,  7],\n",
       "  [ 8,  9, 10, 11]],\n",
       " [[12, 13, 14, 15],\n",
       "  [16, 17, 18, 19],\n",
       "  [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ems.arange(24).reshape(2, 3, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[5, 4], dtype=Float32, value=\n",
       " [[ 0.00000000e+00,  1.00000000e+00,  2.00000000e+00,  3.00000000e+00],\n",
       "  [ 4.00000000e+00,  5.00000000e+00,  6.00000000e+00,  7.00000000e+00],\n",
       "  [ 8.00000000e+00,  9.00000000e+00,  1.00000000e+01,  1.10000000e+01],\n",
       "  [ 1.20000000e+01,  1.30000000e+01,  1.40000000e+01,  1.50000000e+01],\n",
       "  [ 1.60000000e+01,  1.70000000e+01,  1.80000000e+01,  1.90000000e+01]]),\n",
       " Tensor(shape=[5, 4], dtype=Float32, value=\n",
       " [[ 0.00000000e+00,  2.00000000e+00,  4.00000000e+00,  6.00000000e+00],\n",
       "  [ 8.00000000e+00,  1.00000000e+01,  1.20000000e+01,  1.40000000e+01],\n",
       "  [ 1.60000000e+01,  1.80000000e+01,  2.00000000e+01,  2.20000000e+01],\n",
       "  [ 2.40000000e+01,  2.60000000e+01,  2.80000000e+01,  3.00000000e+01],\n",
       "  [ 3.20000000e+01,  3.40000000e+01,  3.60000000e+01,  3.80000000e+01]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = ems.arange(20, dtype=mindspore.float32).reshape(5, 4)\n",
    "B = A.copy()\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "两个矩阵的按元素乘法称为*Hadamard积*（Hadamard product）（数学符号$\\odot$）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[5, 4], dtype=Float32, value=\n",
       "[[ 0.00000000e+00,  1.00000000e+00,  4.00000000e+00,  9.00000000e+00],\n",
       " [ 1.60000000e+01,  2.50000000e+01,  3.60000000e+01,  4.90000000e+01],\n",
       " [ 6.40000000e+01,  8.10000000e+01,  1.00000000e+02,  1.21000000e+02],\n",
       " [ 1.44000000e+02,  1.69000000e+02,  1.96000000e+02,  2.25000000e+02],\n",
       " [ 2.56000000e+02,  2.89000000e+02,  3.24000000e+02,  3.61000000e+02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "origin_pos": 50,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[2, 3, 4], dtype=Int32, value=\n",
       " [[[ 2,  3,  4,  5],\n",
       "   [ 6,  7,  8,  9],\n",
       "   [10, 11, 12, 13]],\n",
       "  [[14, 15, 16, 17],\n",
       "   [18, 19, 20, 21],\n",
       "   [22, 23, 24, 25]]]),\n",
       " (2, 3, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = ems.arange(24).reshape(2, 3, 4)\n",
    "a + X, (a * X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "计算其元素的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "origin_pos": 54,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[4], dtype=Float32, value= [ 0.00000000e+00,  1.00000000e+00,  2.00000000e+00,  3.00000000e+00]),\n",
       " Tensor(shape=[], dtype=Float32, value= 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ems.arange(4, dtype=mindspore.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "表示任意形状张量的元素和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "origin_pos": 58,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 4), Tensor(shape=[], dtype=Float32, value= 190))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "指定张量沿哪一个轴来通过求和降低维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "origin_pos": 62,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[4], dtype=Float32, value= [ 4.00000000e+01,  4.50000000e+01,  5.00000000e+01,  5.50000000e+01]),\n",
       " (4,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis0, A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "origin_pos": 66,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[5], dtype=Float32, value= [ 6.00000000e+00,  2.20000000e+01,  3.80000000e+01,  5.40000000e+01,  7.00000000e+01]),\n",
       " (5,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis1 = A.sum(axis=1)\n",
    "A_sum_axis1, A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "origin_pos": 70,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[], dtype=Float32, value= 190)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "一个与求和相关的量是*平均值*（mean或average）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "origin_pos": 74,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[], dtype=Float32, value= 9.5),\n",
       " Tensor(shape=[], dtype=Float32, value= 9.5))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "origin_pos": 78,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[4], dtype=Float32, value= [ 8.00000000e+00,  9.00000000e+00,  1.00000000e+01,  1.10000000e+01]),\n",
       " Tensor(shape=[4], dtype=Float32, value= [ 8.00000000e+00,  9.00000000e+00,  1.00000000e+01,  1.10000000e+01]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "计算总和或均值时保持轴数不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "origin_pos": 82,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[5, 1], dtype=Float32, value=\n",
       "[[ 6.00000000e+00],\n",
       " [ 2.20000000e+01],\n",
       " [ 3.80000000e+01],\n",
       " [ 5.40000000e+01],\n",
       " [ 7.00000000e+01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "通过广播将`A`除以`sum_A`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "origin_pos": 86,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[5, 4], dtype=Float32, value=\n",
       "[[ 0.00000000e+00,  1.66666672e-01,  3.33333343e-01,  5.00000000e-01],\n",
       " [ 1.81818187e-01,  2.27272734e-01,  2.72727281e-01,  3.18181813e-01],\n",
       " [ 2.10526317e-01,  2.36842111e-01,  2.63157904e-01,  2.89473683e-01],\n",
       " [ 2.22222224e-01,  2.40740746e-01,  2.59259254e-01,  2.77777791e-01],\n",
       " [ 2.28571430e-01,  2.42857143e-01,  2.57142872e-01,  2.71428585e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "某个轴计算`A`元素的累积总和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "origin_pos": 90,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[5, 4], dtype=Float32, value=\n",
       "[[ 0.00000000e+00,  1.00000000e+00,  2.00000000e+00,  3.00000000e+00],\n",
       " [ 4.00000000e+00,  6.00000000e+00,  8.00000000e+00,  1.00000000e+01],\n",
       " [ 1.20000000e+01,  1.50000000e+01,  1.80000000e+01,  2.10000000e+01],\n",
       " [ 2.40000000e+01,  2.80000000e+01,  3.20000000e+01,  3.60000000e+01],\n",
       " [ 4.00000000e+01,  4.50000000e+01,  5.00000000e+01,  5.50000000e+01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "点积是相同位置的按元素乘积的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "origin_pos": 94,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[4], dtype=Float32, value= [ 0.00000000e+00,  1.00000000e+00,  2.00000000e+00,  3.00000000e+00]),\n",
       " Tensor(shape=[4], dtype=Float32, value= [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00]),\n",
       " Tensor(shape=[], dtype=Float32, value= 6))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ems.ones(4, dtype = mindspore.float32)\n",
    "x, y, ems.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "origin_pos": 98,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[], dtype=Float32, value= 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ems.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "矩阵向量积$\\mathbf{A}\\mathbf{x}$是一个长度为$m$的列向量，\n",
    "其第$i$个元素是点积$\\mathbf{a}^\\top_i \\mathbf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "origin_pos": 105,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 4),\n",
       " (4,),\n",
       " Tensor(shape=[5], dtype=Float32, value= [ 1.40000000e+01,  3.80000000e+01,  6.20000000e+01,  8.60000000e+01,  1.10000000e+02]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, ems.dot(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "我们可以将矩阵-矩阵乘法$\\mathbf{AB}$看作是简单地执行$m$次矩阵-向量积，并将结果拼接在一起，形成一个$n \\times m$矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "origin_pos": 109,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[5, 3], dtype=Float32, value=\n",
       "[[ 6.00000000e+00,  6.00000000e+00,  6.00000000e+00],\n",
       " [ 2.20000000e+01,  2.20000000e+01,  2.20000000e+01],\n",
       " [ 3.80000000e+01,  3.80000000e+01,  3.80000000e+01],\n",
       " [ 5.40000000e+01,  5.40000000e+01,  5.40000000e+01],\n",
       " [ 7.00000000e+01,  7.00000000e+01,  7.00000000e+01]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = ems.ones((4, 3))\n",
    "ems.matmul(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$L_2$*范数*是向量元素平方和的平方根：\n",
    "$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "origin_pos": 113,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[], dtype=Float32, value= 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = ems.tensor([3.0, -4.0], dtype=mindspore.float32)\n",
    "ems.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$L_1$范数，它表示为向量元素的绝对值之和：\n",
    "$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "origin_pos": 117,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[], dtype=Float32, value= 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ems.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "矩阵\n",
    "的*Frobenius范数*（Frobenius norm）是矩阵元素平方和的平方根：\n",
    "$$\\|\\mathbf{X}\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "origin_pos": 121,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[], dtype=Float32, value= 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ems.norm(ems.ones((4, 9)))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
